{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import signal\n",
    "from scipy import linalg\n",
    "import scipy.sparse as sp\n",
    "import healpy as hp\n",
    "import pickle\n",
    "\n",
    "plt.rc(\"savefig\", dpi=300)\n",
    "\n",
    "# Common variables\n",
    "nside = 16\n",
    "npix = hp.nside2npix(nside)\n",
    "tol = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised Mean Squared Error (NMSE)\n",
    "def NMSE (arr, map_inj):\n",
    "    return ((arr-map_inj).dot(arr-map_inj)/(map_inj.dot(map_inj)))\n",
    "\n",
    "# Normalised Scalar Product\n",
    "def NSP(source_map, clean_map):\n",
    "    return (source_map.dot(clean_map)/np.sqrt(source_map.dot(source_map)*clean_map.dot(clean_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam matrix and Hessian aka C\n",
    "C = np.loadtxt('Hess'+str(npix)+'.txt')\n",
    "B = np.loadtxt('FBeamNew_'+str(npix)+'.txt')\n",
    "\n",
    "#print (B[100,200],B[200,100],B[100,100],B[200,200])\n",
    "\n",
    "# Hessian for norm regularisation\n",
    "Cn = np.identity(npix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir='fig/'\n",
    "saveFigs = True\n",
    "\n",
    "import pylab\n",
    "import matplotlib.colors\n",
    "\n",
    "# Histogram equalised colormap\n",
    "# From https://stackoverflow.com/questions/5858902/histogram-equalization-of-matplotlib-color-tables\n",
    "imvals = np.sort(B.flatten())\n",
    "#vals = (imvals - np.min(imvals))/np.max(imvals)*256.0\n",
    "#imvals = vals.astype(int)\n",
    "lo = imvals[0]\n",
    "hi = imvals[-1]\n",
    "steps = (imvals[::int(len(imvals)/16)] - lo) / (hi - lo)\n",
    "num_steps = float(len(steps))\n",
    "interps = [(s, idx/num_steps, idx/num_steps) for idx, s in enumerate(steps)]\n",
    "interps.append((1, 1, 1))\n",
    "cdict = {'red' : interps,\n",
    "         'green' : interps,\n",
    "         'blue' : interps}\n",
    "histeq_cmap = matplotlib.colors.LinearSegmentedColormap('HistEq', cdict)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(B,interpolation=\"none\",cmap=histeq_cmap)\n",
    "plt.colorbar()\n",
    "plt.axis([0,npix,0,npix])\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'beamMatrix.png',bbox_inches = 'tight',pad_inches = 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(C)\n",
    "plt.colorbar()\n",
    "plt.axis([0,npix,0,npix])\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'Hessian.png',bbox_inches = 'tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise\n",
    "\n",
    "noiseScale = 0.25\n",
    "\n",
    "## Covariance Matrix\n",
    "#N = (0.25) * B\n",
    "#\n",
    "## Generate noise maps (this needs to be run only once to generate the noise files)\n",
    "#nsim = 1000\n",
    "#for i in range(nsim):\n",
    "#    np.random.seed(i)\n",
    "#    noise = np.random.multivariate_normal(np.zeros(npix),N)\n",
    "#    np.savetxt('noise/noiseMap_'+str(npix)+'_'+str(i)+'.txt',noise)\n",
    "\n",
    "noise0 = noiseScale * np.loadtxt('noise/noiseMap_'+str(npix)+'_117.txt')\n",
    "hp.mollview(noise0)\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'noise.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point source\n",
    "inj_pix = 736\n",
    "#inj_pix = [799, 800, 801]\n",
    "x = 0.05 # variable_source strength (0.5, 0.1, 0.05)\n",
    "\n",
    "# Injection map\n",
    "inj_map = np.zeros(npix)\n",
    "inj_map[inj_pix] = x\n",
    "hp.mollview(inj_map, title='Source Map')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'source-point'+str(x)+'.pdf')\n",
    "\n",
    "# Dirty Map\n",
    "dirty_map = B.dot(inj_map) + noise0\n",
    "hp.mollview(dirty_map, title='Dirty Map')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'dirty-point'+str(x)+'.pdf')\n",
    "\n",
    "nmse_dirty = NMSE (dirty_map, B.dot(inj_map))\n",
    "nsp_dirty = NSP (dirty_map, B.dot(inj_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Point source: Plot NMSE and NSP vs number of iterations to find the optimal number of iteration\n",
    "niter = 20\n",
    "nmse_noreg_vs_iter = np.zeros(niter)\n",
    "nsp_noreg_vs_iter = np.zeros(niter)\n",
    "for iiter in range(niter):\n",
    "    clean_map = sp.linalg.cgs(B, dirty_map, tol = tol, maxiter = iiter+1)\n",
    "    nmse_noreg_vs_iter[iiter] = NMSE (clean_map[0],inj_map)\n",
    "    nsp_noreg_vs_iter[iiter] = NSP (clean_map[0],inj_map)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nmse_noreg_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Point Source: No regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nmse_no-reg_vs_iter_point'+str(x)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nsp_noreg_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NSP')\n",
    "plt.title('Point Source: No regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nsp_no-reg_vs_iter_point'+str(x)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Optimum number of iterations\n",
    "opt_iters_noreg = np.argmin(nmse_noreg_vs_iter) + 1\n",
    "print (\"Optimum number of iterations: \", opt_iters_noreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Source: Unregularised deconvolution\n",
    "#iters_noreg = opt_iters_noreg\n",
    "iters_noreg = 3\n",
    "\n",
    "# Clean Map: DECONVOLUTION WITHOUT REGULARIZATION:\n",
    "clean_map = sp.linalg.cgs(B, dirty_map, tol = tol, maxiter = iters_noreg)\n",
    "hp.mollview(clean_map[0], title='Clean Map: Unregularised, #iterations = '+str(iters_noreg))\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_no-reg_point'+str(x)+'_iters'+str(iters_noreg)+'.pdf')\n",
    "nmse_noreg = NMSE (clean_map[0],inj_map)\n",
    "nsp_noreg = NSP (clean_map[0],inj_map)\n",
    "print (nmse_noreg,nsp_noreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Source: Plot NMSE and NSP vs lambda to find the optimal regularisation strength\n",
    "maxiter = 50\n",
    "\n",
    "maxlamb = 1e6\n",
    "minlamb = 1\n",
    "nlambda = 100\n",
    "alambda = np.logspace(np.log10(minlamb), np.log10(maxlamb), nlambda, endpoint=True)\n",
    "#alambda = np.linspace(minlamb, maxlamb, nlambda, endpoint=True)\n",
    "\n",
    "nmse_norm_vs_lambda = np.zeros(nlambda)\n",
    "nsp_norm_vs_lambda = np.zeros(nlambda)\n",
    "for ilambda in range(nlambda):\n",
    "    clean_map_norm = sp.linalg.cgs((B+alambda[ilambda]*Cn),dirty_map,tol = tol, maxiter = maxiter)\n",
    "    nmse_norm_vs_lambda[ilambda] = NMSE (clean_map_norm[0],inj_map)\n",
    "    nsp_norm_vs_lambda[ilambda]  = NSP (clean_map_norm[0],inj_map)\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(alambda,nmse_norm_vs_lambda)\n",
    "plt.xlabel('Regularisation strength')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Point Source: Norm Regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nmse_norm_vs_lambda_point'+str(x)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(alambda,nsp_norm_vs_lambda)\n",
    "plt.xlabel('Regularisation strength')\n",
    "plt.ylabel('NSP')\n",
    "plt.title('Point Source: Norm Regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nsp_norm_vs_lambda_point'+str(x)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Optimal lambda\n",
    "optlamb_point = alambda[np.argmin(nmse_norm_vs_lambda)]\n",
    "print (\"Optimum regularisation strength for point source with norm regularisation: \", optlamb_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point source: Regularisation strength\n",
    "#lamb = optlamb_point\n",
    "lamb = 1000\n",
    "\n",
    "# Clean Map: DECONVOLUTION With Norm Regularisation:\n",
    "clean_map_norm = sp.linalg.cgs(B+lamb*Cn, dirty_map, tol = tol, maxiter = maxiter)\n",
    "hp.mollview(clean_map_norm[0], title='Clean Map: Norm regularisation with strength '+str(lamb))\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_norm-reg_point'+str(x)+'_lambda'+str(lamb)+'.pdf')\n",
    "nmse_norm = NMSE (clean_map_norm[0],inj_map)\n",
    "nsp_norm = NSP (clean_map_norm[0],inj_map)\n",
    "\n",
    "# DECONVOLUTION With Grad Regularisation:\n",
    "clean_map_grad = sp.linalg.cgs(B+lamb*C, dirty_map, tol = tol, maxiter = maxiter)\n",
    "hp.mollview(clean_map_grad[0], title='Clean Map: Gradient regularisation with strength = '+str(lamb))\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_grad-reg_point'+str(x)+'_lambda'+str(lamb)+'.pdf')\n",
    "nmse_grad = NMSE (clean_map_grad[0],inj_map)\n",
    "nsp_grad = NSP (clean_map_grad[0],inj_map)\n",
    "\n",
    "print (x,'&', iters_noreg,'&',lamb,'&', \\\n",
    "       \"%7.4F\" %(nsp_dirty),'&', \"%7.4F\" %(nsp_noreg),'&', \"%7.4F\" %(nsp_norm),'&', \"%7.4F\" %(nsp_grad),'&',\\\n",
    "       \"%9.4F\" %(nmse_dirty),'&', \"%9.4F\" %(nmse_noreg),'&', \"%9.4F\" %(nmse_norm),'&', \"%9.4F\" %(nmse_grad), '\\\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Source: Masked maps\n",
    "\n",
    "# Dirty map\n",
    "dirty_map_sigma = np.std(dirty_map)\n",
    "\n",
    "dirty_map_2s = dirty_map.copy()\n",
    "dirty_map_2s[dirty_map_2s < 2.0*dirty_map_sigma] = 0.0\n",
    "hp.mollview(dirty_map_2s, title='Dirty Map: 2-sigma mask')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'dirty-point'+str(x)+'_2sigma-mask.pdf')\n",
    "dirty_map_3s = dirty_map.copy()\n",
    "dirty_map_3s[dirty_map_3s < 3.0*dirty_map_sigma] = 0.0\n",
    "hp.mollview(dirty_map_3s, title='Dirty Map: 3-sigma mask')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'dirty-point'+str(x)+'_3sigma-mask.pdf')\n",
    "\n",
    "# Unregularised Clean Map\n",
    "clean_map_sigma = np.std(clean_map[0])\n",
    "clean_map_2s = clean_map[0].copy()\n",
    "clean_map_2s[clean_map_2s < 2.0*clean_map_sigma] = 0.0\n",
    "hp.mollview(clean_map_2s, title='Unregularised Clean Map: 2-sigma mask')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_no-reg_point'+str(x)+'_iters'+str(iters_noreg)+'_2sigma-mask.pdf')\n",
    "clean_map_3s = clean_map[0].copy()\n",
    "clean_map_3s[clean_map_3s < 3.0*clean_map_sigma] = 0.0\n",
    "hp.mollview(clean_map_3s, title='Unregularised Clean Map: 3-sigma mask')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_no-reg_point'+str(x)+'_iters'+str(iters_noreg)+'_3sigma-mask.pdf')\n",
    "\n",
    "# Norm regularised Clean Map\n",
    "clean_map_norm_sigma = np.std(clean_map_norm[0])\n",
    "clean_map_norm_2s = clean_map_norm[0].copy()\n",
    "clean_map_norm_2s[clean_map_norm_2s < 2.0*clean_map_norm_sigma] = 0.0\n",
    "hp.mollview(clean_map_norm_2s, title='Norm regularised Clean Map: 2-sigma mask')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_norm-reg_point'+str(x)+'_lambda'+str(lamb)+'_2sigma-mask.pdf')\n",
    "clean_map_norm_3s = clean_map_norm[0].copy()\n",
    "clean_map_norm_3s[clean_map_norm_3s < 3.0*clean_map_norm_sigma] = 0.0\n",
    "hp.mollview(clean_map_norm_3s, title='Norm regularised Clean Map: 3-sigma mask')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_norm-reg_point'+str(x)+'_lambda'+str(lamb)+'_3sigma-mask.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Source: Stability of Deconvolution\n",
    "niter = maxiter\n",
    "nmse_norm_vs_iter = np.zeros(niter)\n",
    "nsp_norm_vs_iter = np.zeros(niter)\n",
    "for iiter in range(niter):\n",
    "    clean_map_norm = sp.linalg.cgs(B+lamb*Cn, dirty_map, tol = tol, maxiter = iiter+1)\n",
    "    nmse_norm_vs_iter[iiter] = NMSE (clean_map_norm[0],inj_map)\n",
    "    nsp_norm_vs_iter[iiter] = NSP (clean_map_norm[0],inj_map)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nmse_norm_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Point Source: Norm Regularisation with strength '+str(lamb))\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nmse_norm_vs_iter_point'+str(x)+'_lambda'+str(lamb)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nsp_norm_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NSP')\n",
    "plt.title('Point Source: Norm Regularisation with strength '+str(lamb))\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nsp_norm_vs_iter_point'+str(x)+'_lambda'+str(lamb)+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Point Source: Simulations\n",
    "#iters_noreg = 5\n",
    "#lamb = 1000\n",
    "nsim = 1000   # NUMBER OF ELEMENTS\n",
    "strengthRange = [0.05,0.1]\n",
    "sourceStrength = np.zeros(nsim)\n",
    "injPix = np.zeros(nsim)\n",
    "nmse_norm = np.zeros(nsim)\n",
    "nmse_unreg = np.zeros(nsim)\n",
    "inj_map = np.zeros(npix)\n",
    "for i in range(nsim):\n",
    "    noise = noiseScale * np.loadtxt('noise/noiseMap_'+str(npix)+'_'+str(i+1)+'.txt')\n",
    "    np.random.seed(i)\n",
    "    sourceStrength[i] = random.uniform(strengthRange[0],strengthRange[1])\n",
    "    randomPix = random.randint(0,npix-1)\n",
    "    injPix[i] = randomPix\n",
    "    inj_map[:] = 0.0\n",
    "    inj_map[randomPix] = sourceStrength[i]\n",
    "    dirty_map = B.dot(inj_map) + noise\n",
    "\n",
    "    # DECONVOLUTION WITHOUT REGULARIZATION:\n",
    "    clean_map = sp.linalg.cgs(B, dirty_map, tol = tol, maxiter = iters_noreg)\n",
    "    nmse_unreg[i] = NMSE(clean_map[0],inj_map)  \n",
    "    # DECONVOLUTION WITH REGULARIZATION:\n",
    "    clean_map_norm = sp.linalg.cgs(B+lamb*Cn, dirty_map, tol = tol, maxiter = maxiter)\n",
    "    nmse_norm[i] = NMSE(clean_map_norm[0],inj_map)\n",
    "    \n",
    "    if np.remainder((i+1),100) == 0:\n",
    "        print (\"%6d\" %(i+1),' of ', \"%6d\" %(nsim),' simulations done')\n",
    "\n",
    "print(min(nmse_unreg - nmse_norm)) # Positive value will mean regularisation is always better\n",
    "\n",
    "np.savetxt('point_norm_sims_lambda'+str(lamb)+'.txt',\\\n",
    "           np.column_stack((injPix, sourceStrength, nmse_unreg, nmse_norm)))\n",
    "\n",
    "n, bins, patches = plt.hist((nmse_norm, nmse_unreg, nmse_unreg - nmse_norm), bins=20,\\\n",
    "                            label=['Norm regularisation','No regularisation','Without - With Regularisation'],\\\n",
    "                            color=['tab:green','tab:orange','tab:blue'])\n",
    "hatches = ['//', '--', '']\n",
    "for patch_set, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch_set, hatch=hatch)\n",
    "plt.legend()\n",
    "plt.xlabel('NMSE')\n",
    "plt.title('Histogram for point sources: Regularisation strength '+str(lamb))\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'hist_point_norm_lambda'+str(lamb)+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended source\n",
    "y = 0.01 # Source strength (0.1, 0.025, 0.01)\n",
    "\n",
    "sourceMap = np.loadtxt('FSource_galaxy.txt')\n",
    "inj_map_ext = (y / max(sourceMap)) * sourceMap\n",
    "hp.mollview(inj_map_ext, title='Source Map')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'source-ext'+str(y)+'.pdf')\n",
    "\n",
    "dirty_map_ext = B.dot(inj_map_ext) + noise0\n",
    "hp.mollview(dirty_map_ext, title='Dirty Map')\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'dirty-ext'+str(y)+'.pdf')\n",
    "\n",
    "nmse_dirty = NMSE (dirty_map_ext, B.dot(inj_map_ext))\n",
    "nsp_dirty = NSP (dirty_map_ext, B.dot(inj_map_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended source: Plot NMSE and NSP vs number of iterations to find the optimal number of iterations\n",
    "niter = 100\n",
    "nmse_noreg_vs_iter = np.zeros(niter)\n",
    "nsp_noreg_vs_iter = np.zeros(niter)\n",
    "for iiter in range(niter):\n",
    "    clean_map_ext = sp.linalg.cgs(B, dirty_map_ext, tol = tol, maxiter = iiter+1)\n",
    "    nmse_noreg_vs_iter[iiter] = NMSE (clean_map_ext[0],inj_map_ext)\n",
    "    nsp_noreg_vs_iter[iiter]  = NSP (clean_map_ext[0],inj_map_ext)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nmse_noreg_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Extended Source: No regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nmse_no-reg_vs_iter_ext'+str(y)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nsp_noreg_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NSP')\n",
    "plt.title('Extended Source: No regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nsp_no-reg_vs_iter_ext'+str(y)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Optimum number of iterations\n",
    "opt_iters_noreg_ext = np.argmax(nsp_noreg_vs_iter) + 1\n",
    "print (\"Optimum number of iterations: \", opt_iters_noreg_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended Source: Unregularised deconvolution\n",
    "#iters_noreg = opt_iters_noreg_ext\n",
    "iters_noreg = 3\n",
    "\n",
    "# Clean Map: DECONVOLUTION WITHOUT REGULARIZATION:\n",
    "clean_map_ext = sp.linalg.cgs(B, dirty_map_ext, tol = tol, maxiter = iters_noreg)\n",
    "hp.mollview(clean_map_ext[0], title='Clean Map: Unregularised, #iterations = '+str(iters_noreg))\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_no-reg_ext'+str(y)+'_iters'+str(iters_noreg)+'.pdf')\n",
    "nmse_noreg = NMSE (clean_map_ext[0],inj_map_ext)\n",
    "nsp_noreg = NSP (clean_map_ext[0],inj_map_ext)\n",
    "print (nmse_noreg,nsp_noreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended Source: Plot NMSE and NSP vs lambda to find the optimal regularisation strength\n",
    "maxiter = 100\n",
    "\n",
    "maxlamb = 1e6\n",
    "minlamb = 1\n",
    "nlambda = 100\n",
    "alambda = np.logspace(np.log10(minlamb), np.log10(maxlamb), nlambda, endpoint=True)\n",
    "#alambda = np.linspace(minlamb, maxlamb, nlambda, endpoint=True)\n",
    "\n",
    "nmse_grad_vs_lambda = np.zeros(nlambda)\n",
    "nsp_grad_vs_lambda = np.zeros(nlambda)\n",
    "for ilambda in range(nlambda):\n",
    "    clean_map_grad_ext = sp.linalg.cgs((B+alambda[ilambda]*C),dirty_map_ext,tol = tol, maxiter = maxiter)\n",
    "    nmse_grad_vs_lambda[ilambda] = NMSE (clean_map_grad_ext[0],inj_map_ext)\n",
    "    nsp_grad_vs_lambda[ilambda]  = NSP (clean_map_grad_ext[0],inj_map_ext)\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(alambda,nmse_grad_vs_lambda)\n",
    "plt.xlabel('Regularisation strength')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Extended Source: Gradient Regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nmse_grad_vs_lambda_ext'+str(y)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(alambda,nsp_grad_vs_lambda)\n",
    "plt.xlabel('Regularisation strength')\n",
    "plt.ylabel('NSP')\n",
    "plt.title('Extended Source: Gradient Regularisation')\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nsp_grad_vs_lambda_ext'+str(y)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Optimal lambda\n",
    "optlamb_ext = alambda[np.argmax(nsp_grad_vs_lambda)]\n",
    "print (\"Optimum regularisation strength for extended source with grad regularisation: \", optlamb_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extended source: Regularisation strength\n",
    "#lamb = optlamb_ext\n",
    "lamb = 500\n",
    "\n",
    "# Clean Map: DECONVOLUTION With Norm Regularisation:\n",
    "clean_map_norm_ext = sp.linalg.cgs((B+lamb*Cn),dirty_map_ext,tol = tol, maxiter = maxiter)\n",
    "hp.mollview(clean_map_norm_ext[0], title='Clean Map: Norm regularisation with strength = '+str(lamb))\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_norm-reg_ext'+str(y)+'_lambda'+str(lamb)+'.pdf')\n",
    "nmse_norm = NMSE (clean_map_norm_ext[0],inj_map_ext)\n",
    "nsp_norm = NSP (clean_map_norm_ext[0],inj_map_ext)\n",
    "\n",
    "# Clean Map: DECONVOLUTION With gradient Regularisation:\n",
    "clean_map_grad_ext = sp.linalg.cgs((B+lamb*C),dirty_map_ext,tol = tol, maxiter = maxiter)\n",
    "hp.mollview(clean_map_grad_ext[0], title='Clean Map: Gradient regularisation with strength = '+str(lamb))\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'clean_grad-reg_ext'+str(y)+'_lambda'+str(lamb)+'.pdf')\n",
    "nmse_grad = NMSE (clean_map_grad_ext[0],inj_map_ext)\n",
    "nsp_grad = NSP (clean_map_grad_ext[0],inj_map_ext)\n",
    "\n",
    "print (y,'&', iters_noreg,'&', lamb,'&',\\\n",
    "       \"%7.4F\" %(nsp_dirty),'&', \"%7.4F\" %(nsp_noreg),'&', \"%7.4F\" %(nsp_norm),'&', \"%7.4F\" %(nsp_grad),'&',\\\n",
    "       \"%9.4F\" %(nmse_dirty),'&', \"%9.4F\" %(nmse_noreg),'&', \"%9.4F\" %(nmse_norm),'&', \"%9.4F\" %(nmse_grad), '\\\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended Source: Stability of Deconvolution\n",
    "niter = maxiter\n",
    "nmse_grad_vs_iter = np.zeros(niter)\n",
    "nsp_grad_vs_iter = np.zeros(niter)\n",
    "for iiter in range(niter):\n",
    "    clean_map_grad_ext = sp.linalg.cgs(B+lamb*C, dirty_map_ext, tol = tol, maxiter = iiter+1)\n",
    "    nmse_grad_vs_iter[iiter] = NMSE (clean_map_grad_ext[0],inj_map_ext)\n",
    "    nsp_grad_vs_iter[iiter] = NSP (clean_map_grad_ext[0],inj_map_ext)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nmse_grad_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Extended Source: Gradient Regularisation with strength '+str(lamb))\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nmse_grad_vs_iter_ext'+str(x)+'_lambda'+str(lamb)+'.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nsp_grad_vs_iter)\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('NSP')\n",
    "plt.title('Extended Source: Gradient Regularisation with strength '+str(lamb))\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'nsp_grad_vs_iter_ext'+str(y)+'_lambda'+str(lamb)+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended Source: Simulations\n",
    "nsim = 1000   # NUMBER OF ELEMENTS\n",
    "#iters_noreg = 50\n",
    "#lamb = 1000\n",
    "#lmax = 32\n",
    "strengthRange = [0.01,0.05]\n",
    "sourceStrength = np.zeros(nsim)\n",
    "nsp_grad = np.zeros(nsim)\n",
    "nsp_unreg = np.zeros(nsim)    \n",
    "\n",
    "sourceMap0 = np.loadtxt('FSource_galaxy.txt')\n",
    "cl0 = hp.anafast(sourceMap0)\n",
    "\n",
    "for i in range(nsim):\n",
    "    noise = noiseScale * np.loadtxt('noise/noiseMap_'+str(npix)+'_'+str(i+1)+'.txt')\n",
    "    np.random.seed(i)\n",
    "    sourceStrength[i] = random.uniform(strengthRange[0],strengthRange[1])\n",
    "    sourceMap = np.abs(hp.synfast(cl0, nside=nside, verbose=False))\n",
    "    inj_map_ext = (sourceStrength[i]/max(sourceMap)) * sourceMap\n",
    "    dirty_map_ext = B.dot(inj_map_ext) + noise\n",
    "    \n",
    "    clean_map_ext = sp.linalg.cgs(B, dirty_map_ext, tol = tol, maxiter = iters_noreg)\n",
    "    nsp_unreg[i] = NSP(clean_map_ext[0],inj_map_ext)\n",
    "    \n",
    "    clean_map_grad_ext = sp.linalg.cgs(B + lamb*C, dirty_map_ext, tol = tol, maxiter = maxiter)\n",
    "    nsp_grad[i] = NSP(clean_map_grad_ext[0],inj_map_ext)\n",
    "    \n",
    "    if np.remainder((i+1),100) == 0:\n",
    "        print (\"%6d\" %(i+1),' of ', \"%6d\" %(nsim),' simulations done')\n",
    "\n",
    "print(min(nsp_grad - nsp_unreg)) # Positive value will mean regularisation is always better\n",
    "    \n",
    "np.savetxt('ext_grad_sims_lambda'+str(lamb)+'.txt',\\\n",
    "           np.column_stack((sourceStrength, nsp_unreg, nsp_grad)))\n",
    "\n",
    "n, bins, patches = plt.hist((nsp_grad, nsp_unreg, nsp_grad - nsp_unreg), bins=20,\\\n",
    "                            label=['Gradient regularisation', 'No regularisation', 'With - Without Regularisation'],\\\n",
    "                            color=['tab:green','tab:orange','tab:blue'])\n",
    "\n",
    "hatches = ['//', '--', '']\n",
    "for patch_set, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch_set, hatch=hatch)\n",
    "plt.legend()\n",
    "plt.xlabel('NSP')\n",
    "plt.title('Histogram for extended sources: Regularisation strength '+str(lamb))\n",
    "plt.tight_layout()\n",
    "if saveFigs:\n",
    "    plt.savefig(figdir+'hist_ext_grad_lambda'+str(lamb)+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
